{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww25400\viewh13180\viewkind0
\deftab720
\pard\pardeftab720\sl280\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 #Prithvi Lakshminarayanan\
#2-11-2016\
\
import datetime\
import pyspark_cassandra\
from cassandra.cluster import Cluster\
from cassandra.query import BatchStatement\
\
\
def parseline(line):\
    linere = re.compile('^(\\\\S+) - - \\\\[(\\\\S+) [+-]\\\\d+\\\\] \\"[A-Z]+ (\\\\S+) HTTP/\\\\d\\\\.\\\\d\\" \\\\d+ (\\\\d+)$')\
    match = re.search(linere, line)\
    if match:\
        m = re.match(linere, line)\
        host = m.group(1)\
        id = str(uuid.uuid1())\
        dt = datetime.datetime.strptime(m.group(2), '%d/%b/%Y:%H:%M:%S')\
        path = m.group(3)\
        bytes = float(m.group(4))\
        dct = \{'id':id, "host": host, "datetime": dt, "path": path, "bytes": bytes\}\
        return dct\
    return None\
\
input_dir = sys.argv[1]\
keyspace = sys.argv[2]\
\
cluster_seeds = ['199.60.17.136', '199.60.17.173']\
conf = SparkConf().set('spark.cassandra.connection.host', ','.join(cluster_seeds))\
sc = pyspark_cassandra.CassandraSparkContext(conf=conf)\
\
files=sc.textFile(input_dir)\
\
\
maped_lines=files.map(parseline)\
filtered_lines=maped_lines.filter(lambda v: v is not None)\
filtered_lines.saveToCassandra(keyspace,'nasalogs')\
\
\
}