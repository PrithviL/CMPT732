{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl280\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import sys, operator\
import re, string\
from pyspark import SparkConf, SparkContext\
from pyspark.sql import SQLContext, Row\
from pyspark.sql.types import StructType, StructField, StringType,TimestampType\
import datetime\
\
\
def main(sc, sqlContext):\
    LogRow = Row('host', 'date', 'path', 'bytes')\
    def fn_rn(x):\
        host=x[1]\
        date=datetime.datetime.strptime(x[2], '%d/%b/%Y:%H:%M:%S')\
        path=x[3]\
        bytes=x[4]\
        return Row(host=host,date=date,path=path,bytes=bytes)\
    #sqlContext = SQLContext(sc)\
    #sc = SparkContext(conf=conf)\
    schema = StructType([\
        StructField('bytes', StringType(),False),\
        StructField('date', TimestampType(),False),\
        StructField('host', StringType(), False),  \
        StructField('path', StringType(),False)        \
        ])\
\
    text =  sc.textFile(inputs)\
    linere = re.compile("^(\\\\S+) - - \\\\[(\\\\S+) [+-]\\\\d+\\\\] \\"[A-Z]+ (\\\\S+) HTTP/\\\\d\\\\.\\\\d\\" \\\\d+ (\\\\d+)$")\
\
    line=text.map(lambda n:linere.split(n)).filter(lambda x:len(x)==6).map(fn_rn)\
    sqlContext=SQLContext(sc)\
    schemaPeople = sqlContext.createDataFrame(line,schema)\
\
    schemaPeople.write.format('parquet').save(output,mode='overwrite')\
    \
    comments=sqlContext.read.parquet(output)\
    comments.registerTempTable('comments') \
    averages=sqlContext.sql('selecting the bytes as sum')\
    averages.show() \
    \
if __name__ == "__main__":  \
    inputs = sys.argv[1]\
    output = sys.argv[2]\
    conf = SparkConf().setAppName('spark SQL Ingest Logs')\
    sc = SparkContext(conf=conf)\
    sqlContext = SQLContext(sc)\
                                \
}