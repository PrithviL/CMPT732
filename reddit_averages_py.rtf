{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww25400\viewh11340\viewkind0
\deftab720
\pard\pardeftab720\sl280\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 from pyspark import SparkConf, SparkContext\
import json\
\
inputs = sys.argv[1]\
output = sys.argv[2]\
 \
text = sc.textFile(inputs)\
\
conf= SparkConf().setAppName('Reddit Averages')\
sc = SparkContext(conf=conf)\
\
#Converting into JSON Strings\
\
strings = sc.textFile(inputs)\
dictionaries = Json_strings.map(json.loads)\
\
\
#function to add pairs\
\
def add_pairs((a1,b1),(a2,b2)):\
    return (a1+a2,b1+b2)\
\
words=dictionaries.map(lambda line :(line['subreddit'],(float(line['score']),1)))\
\
wordcount = words.reduceByKey(add_pairs).coalesce(1).cache()\
word_Average=wordcount.map(lambda (key,(value,count)):(key,float(value/count)))\
\
json_lines=word_Average.map(lambda line:json.dumps(line))\
json_lines.saveAsTextFile(output)\
}