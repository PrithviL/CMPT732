{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl280\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 #Prithvi Lakshminarayanan\
#4-11-2016\
\
from pyspark import SparkConf\
import pyspark_cassandra\
from pyspark.sql import SQLContext\
\
import sys\
\
cluster_seeds = ['199.60.17.136', '199.60.17.173']\
conf = SparkConf().set('spark.cassandra.connection.host', ','.join(cluster_seeds))\\\
    .set('spark.dynamicAllocation.maxExecutors', 20)\
sc = pyspark_cassandra.CassandraSparkContext(conf=conf)\
sqlContext = SQLContext(sc)\
\
keyspace = sys.argv[1]\
outdir = sys.argv[2]\
orderkeys = sys.argv[3:]\
\
def rdd_for(keyspace, table, split_size=None):\
    rdd = sc.cassandraTable(keyspace, table, split_size=split_size,\
                            row_format=pyspark_cassandra.RowFormat.ROW).setName(table)\
    return rdd\
\
order_items=rdd_for(keyspace,'orders_parts',None)\
\
order_names=order_items.where('orderkey in ?',orderkeys).\\\
    select("orderkey","totalprice","part_names").\\\
    coalesce(1)\
\
res=order_names.map(lambda row :"Order #%s $%.2f: %s "%(row['orderkey'],row['totalprice'],row['part_names']))\\\
    .coalesce(1).cache()\
\
res.saveAsTextFile(outdir)\
}