{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl280\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 from pyspark import SparkConf, SparkContext\
from pyspark.sql import SQLContext\
from pyspark.sql.types import StructType, StructField, StringType, IntegerType\
import sys, operator\
\
inputs = sys.argv[1]\
output = sys.argv[2]\
\
\
\
def main(sqlContext):\
   # inputs = '/Users/Prithvi/Downloads/a1-reddit-1'\
    schema = StructType([StructField('subreddit', StringType(), False),\
                         StructField('score', IntegerType(), False),\
                         ])\
    comments=sqlContext.read.json(inputs,schema)\
    comments.registerTempTable('comments')\
    averages=sqlContext.sql('''select subreddit,AVG(score) from comments group by subreddit''')\
    #averages.show()\
    averages.write.save(output, format='json', mode='overwrite')\
\
if __name__ == "__main__":\
    conf = SparkConf().setAppName('spark SQL')\
    #sqlContext = SQLContext(sc)\
    sc = SparkContext(conf=conf)\
    sqlContext = SQLContext(sc)\
    main(sqlContext)\
}