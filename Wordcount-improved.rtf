{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl280\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 from pyspark import SparkConf, SparkContext\
import sys, operator\
import re, string\
import unicodedata\
\
inputs = sys.argv[1]\
output = sys.argv[2]\
 \
conf = SparkConf().setAppName('word count')\
sc = SparkContext(conf=conf)\
 \
text = sc.textFile(inputs)\
\
wordsep = re.compile(r'[%s\\s]+' % re.escape(string.punctuation))\
words = text.flatMap(lambda line: wordsep.split(line)).filter(lambda w: len(w)>0).map(lambda w: (unicodedata.normalize('NFD',w.lower()),1))\
 \
wordcount = words.reduceByKey(operator.add).coalesce(1).cache()\
 \
outdata = wordcount.sortBy(lambda (w,c): w)\
\
outdatafreq = outdata.sortBy(lambda(w,c):c,False)\
\
outdata_word=outdata.map(lambda(w,c): u"%s %i" % (w, c))\
outdata_frequency=outdatafreq.map(lambda(w,c):u"%s %i" % (w,c))\
\
outdata_word.saveAsTextFile(output + '/by-word')\
outdata_frequency.saveAsTextFile(output + '/by-freq')\
}